{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_grad(coefs, x):\n",
    "    res = 0.0\n",
    "    for i in range(len(coefs)):\n",
    "        res += i * coefs[i] * (x**(i-1))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent(poly, step_size=0.1, iterations=10, x=100.):\n",
    "    x_list = [x]\n",
    "    for i in range(iterations):\n",
    "        x = x - (step_size * poly_grad(poly, x))\n",
    "        x_list.append(x)\n",
    "    return x_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs the `grad_descent` function and will plot \n",
    "# the \"trajectory\" of the x-values visited\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "x_list = grad_descent([15, 0, 2])\n",
    "colors = ['lightgreen'] + ['lightgray'] * (len(x_list) - 2) + ['r']\n",
    "\n",
    "ax.plot(np.linspace(-100, 100, 1001), 2*(np.linspace(-100, 100, 1001)**2) + 15)\n",
    "ax.plot(x_list, [2*(x**2) + 15 for x in x_list], c='r', ls='--')\n",
    "ax.scatter(x_list, [2*(x**2) + 15 for x in x_list], c=colors, s=100, zorder=1000)\n",
    "ax.text(-75, 20000, 'Start: {:.2f}'.format(x_list[0]), color='green')\n",
    "ax.text(-75, 19200, 'End:   {:.2f}'.format(x_list[-1]), color='red')\n",
    "ax.set_ylabel(r\"$L(x)$\")\n",
    "ax.set_xlabel(r\"$x$\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "x_list = grad_descent([15, 0, 2], step_size=0.4)\n",
    "colors = ['lightgreen'] + ['lightgray'] * (len(x_list) - 2) + ['r']\n",
    "\n",
    "ax.plot(np.linspace(-100, 100, 1001), 2*(np.linspace(-100, 100, 1001)**2) + 15)\n",
    "ax.plot(x_list, [2*(x**2) + 15 for x in x_list], c='r', ls='--')\n",
    "ax.scatter(x_list, [2*(x**2) + 15 for x in x_list], c=colors, s=100, zorder=1000)\n",
    "ax.text(-75, 20000, 'Start: {:.2f}'.format(x_list[0]), color='green')\n",
    "ax.text(-75, 19200, 'End:   {:.2f}'.format(x_list[-1]), color='red')\n",
    "ax.set_ylabel(r\"$L(x)$\")\n",
    "ax.set_xlabel(r\"$x$\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "x_list = grad_descent([15, 0, 2], step_size=0.6, x=3) \n",
    "colors = ['lightgreen'] + ['lightgray'] * (len(x_list) - 2) + ['r']\n",
    "\n",
    "ax.plot(np.linspace(-100, 100, 1001), 2*(np.linspace(-100, 100, 1001)**2) + 15)\n",
    "ax.plot(x_list, [2*(x**2) + 15 for x in x_list], c='r', ls='--')\n",
    "ax.scatter(x_list[::-1], [2*(x**2) + 15 for x in x_list][::-1], c=colors[::-1], s=100, zorder=1000)\n",
    "ax.text(-75, 20000, 'Start: {:.2f}'.format(x_list[0]), color='green')\n",
    "ax.text(-75, 19200, 'End:   {:.2f}'.format(x_list[-1]), color='red');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the gradient descent for a non-convex function\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "x = np.linspace(-1.5, 2, 1001)\n",
    "\n",
    "def f(x):\n",
    "    return 1 + x - (x ** 2) - (x ** 3) + (x ** 4)\n",
    "\n",
    "x_list = grad_descent([1, 1, -1, -1, 1], x=2, step_size=0.03)\n",
    "colors = ['lightgreen'] + ['lightgray'] * (len(x_list) - 2) + ['r']\n",
    "\n",
    "ax.plot(x, f(x))\n",
    "ax.plot(x_list, [f(x) for x in x_list], c='r', ls='--')\n",
    "ax.scatter(x_list, [f(x) for x in x_list], c=colors, s=100, zorder=1000)\n",
    "ax.text(-1, 7, 'Start: {:.2f}'.format(x_list[0]), color='green')\n",
    "ax.text(-1, 6.8, 'End:   {:.2f}'.format(x_list[-1]), color='red')\n",
    "ax.set_ylabel(r\"$L(x)$\")\n",
    "ax.set_xlabel(r\"$x$\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Box Office Sales': [85.1, 106.3, 50.2, 130.6, 54.8, 30.3, 79.4, 91.0, 135.4, 89.3],\n",
    "    'Production Costs': [8.5, 12.9, 5.2, 10.7, 3.1, 3.5, 9.2, 9.0, 15.1, 10.2],\n",
    "    'Promotion Costs': [5.1, 5.8, 2.1, 8.4, 2.9, 1.2, 3.7, 7.6, 7.7, 4.5],\n",
    "    'Book Sales': [4.7, 8.8, 15.1, 12.2, 10.6, 3.5, 9.7, 5.9, 20.8, 7.9]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "for var, ax in zip(['Production Costs', 'Promotion Costs', 'Book Sales'], axes):\n",
    "    ax.scatter(data[var], data['Box Office Sales'])\n",
    "    ax.set_xlabel(var + ' (millions)')\n",
    "    ax.grid(True)\n",
    "    if var == 'Production Costs':\n",
    "        ax.set_ylabel('Box Office Sales (millions)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_and_gradient(X, A, y):\n",
    "    N = X.shape[0]\n",
    "    yp = X.dot(A)\n",
    "    loss = np.sum((y - yp) ** 2) / N\n",
    "    gradient = -2 * X.T.dot(y - yp) / N\n",
    "    return loss, gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Box Office Sales': [85.1, 106.3, 50.2, 130.6, 54.8, 30.3, 79.4, 91.0, 135.4, 89.3],\n",
    "    'Production Costs': [8.5, 12.9, 5.2, 10.7, 3.1, 3.5, 9.2, 9.0, 15.1, 10.2],\n",
    "    'Promotion Costs': [5.1, 5.8, 2.1, 8.4, 2.9, 1.2, 3.7, 7.6, 7.7, 4.5],\n",
    "    'Book Sales': [4.7, 8.8, 15.1, 12.2, 10.6, 3.5, 9.7, 5.9, 20.8, 7.9]\n",
    "}\n",
    "\n",
    "# Initialize the four model parameters as random numbers distributed near 0.\n",
    "N = len(data['Box Office Sales'])\n",
    "y = np.array(data['Box Office Sales'])\n",
    "X = np.vstack([np.ones(N), data['Production Costs'], data['Promotion Costs'], data['Book Sales']]).T\n",
    "A = np.random.normal(size=(4,)) # the four model parameters\n",
    "\n",
    "# store the loss values recorded during training\n",
    "losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 0.001\n",
    "iterations = 400\n",
    "losses = list()\n",
    "\n",
    "for _ in range(iterations):\n",
    "    loss, grad = loss_and_gradient(X, A, y)\n",
    "    A -= step_size * grad\n",
    "    losses.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss as it changed during training\n",
    "# note that the y-axis is plotted on a log-scale\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "ax.plot(losses)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xlabel(\"Training Step\");\n",
    "ax.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize what weighting your model learned\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.barh(np.arange(3), A[1:])\n",
    "ax.set_yticks([0, 1, 2])\n",
    "ax.set_yticklabels(['Production Costs', 'Promotion Costs', 'Book Sales'])\n",
    "ax.set_xlabel(\"Learned Weights\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prom = X[:, (0, 2)]\n",
    "A_prom = np.random.normal(size=(2,))\n",
    "\n",
    "step_size = 0.001\n",
    "iterations = 400\n",
    "\n",
    "# perform the same training as before, but\n",
    "# use `X_prom` and `A_prom` as the data and model weights\n",
    "step_size = 0.001\n",
    "iterations = 400\n",
    "\n",
    "for _ in range(iterations):\n",
    "    loss, grad = loss_and_gradient(X_prom, A_prom, y)\n",
    "    A_prom -= step_size * grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the linear model that was\n",
    "# learned to map promotional costs to predicted box office sales\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "ax.scatter(data['Promotion Costs'], data['Box Office Sales'])\n",
    "x_dat = np.array([min(data['Promotion Costs']), max(data['Promotion Costs'])])\n",
    "y_dat = [A_prom[0] + A_prom[1] * x for x in x_dat]\n",
    "ax.plot(x_dat, y_dat, c='r')\n",
    "ax.set_xlabel(\"Promotional Costs (millions)\")\n",
    "ax.set_ylabel(\"Box Office Sales (millions)\")\n",
    "pass\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
